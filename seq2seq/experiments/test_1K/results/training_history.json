{
  "experiment_info": {
    "model_type": "lstm",
    "experiment_dir": "experiments/test_1K",
    "start_time": "2025-09-02T10:48:17.641260",
    "model_params": 12085060
  },
  "config": {
    "model_config": {
      "model_type": "lstm",
      "vocab_size": 28996,
      "embedding_dim": 128,
      "hidden_dim": 256,
      "n_layers": 2,
      "dropout": 0.2
    },
    "training_config": {
      "learning_rate": "3e-4",
      "batch_size": 2,
      "epochs": 1,
      "optimizer": "adam",
      "patience": 10,
      "grad_clip": 1.0,
      "output_dir": "experiments",
      "experiment_name": "test_1K",
      "save_dir": "experiments/test_1K/checkpoints",
      "logs_dir": "experiments/test_1K/logs",
      "save_best_only": true,
      "save_final": true,
      "save_epoch_checkpoints": false,
      "debug_batch_prep": false
    },
    "data_config": {
      "data_path": "datasets/finals/dfs/filtered_sequences_case_study_sample_1K.csv",
      "test_size": 0.2,
      "random_state": 42,
      "target_column": "sequence"
    }
  },
  "results": {
    "train_loss": [
      3.7019873321056367
    ],
    "val_loss": [
      2.795854961872101
    ],
    "test_loss": 2.8000707912445066,
    "total_training_time": 17.627625703811646,
    "best_val_loss": 2.795854961872101,
    "experiment_dir": "experiments/test_1K"
  }
}