{
  "experiment_info": {
    "model_type": "lstm",
    "experiment_dir": "experiments/lstm-50-epochs-48-batch-size",
    "start_time": "2025-11-02T10:09:45.738630",
    "model_params": 12085060
  },
  "config": {
    "model_config": {
      "model_type": "lstm",
      "vocab_size": 28996,
      "embedding_dim": 128,
      "hidden_dim": 256,
      "n_layers": 2,
      "dropout": 0.2
    },
    "training_config": {
      "learning_rate": "3e-4",
      "batch_size": 48,
      "epochs": 50,
      "optimizer": "adam",
      "patience": 10,
      "grad_clip": 1.0,
      "output_dir": "experiments",
      "experiment_name": "lstm-50-epochs-48-batch-size",
      "save_dir": "experiments/lstm-50-epochs-48-batch-size/checkpoints",
      "logs_dir": "experiments/lstm-50-epochs-48-batch-size/logs",
      "save_best_only": true,
      "save_final": true,
      "save_epoch_checkpoints": false,
      "debug_batch_prep": false
    },
    "data_config": {
      "data_path": "datasets/finals/dfs/penalty_w_block.csv",
      "test_size": 0.2,
      "random_state": 42,
      "target_column": "sequence"
    }
  },
  "results": {
    "train_loss": [
      2.115563198176621,
      0.48349277982080757,
      0.4522754716008043,
      0.44566355847625366,
      0.44284030225768034,
      0.4413794596841521,
      0.4404925247902804,
      0.4399012830048768,
      0.4395190179347992,
      0.441829604680154,
      0.43905525906617765,
      0.4391003422510662,
      0.438756517501371,
      0.4386773430041595,
      0.43862641115326,
      0.43854131136912544,
      0.43850733045580037,
      0.4387716501474126,
      0.4383461577151857,
      0.4383170660048437,
      0.4382999914369308,
      0.4382672104089975,
      0.4382620079158592,
      0.438224152796042,
      0.4382057167041009,
      0.4382517335254584,
      0.43814386906084407,
      0.4381414644555323,
      0.43813951235570675,
      0.4381140533480853,
      0.43811729652141174,
      0.4380994753051338,
      0.4380910351411256,
      0.4381087322181673,
      0.43804104926746457,
      0.43804323154808744,
      0.43803897220144405,
      0.43803093349412003,
      0.4380338476968804,
      0.4380214158346203,
      0.4380083140721316,
      0.4380037178033953,
      0.43799294898705904,
      0.43799566786851546,
      0.43801865414214364,
      0.4379678058776937,
      0.4379634935420758,
      0.43795849683445065,
      0.4379711066836863,
      0.4379681178001864
    ],
    "val_loss": [
      0.5404979923938183,
      0.4540413236364405,
      0.4447942519441564,
      0.4414950864112124,
      0.4400963823846046,
      0.4393733739852905,
      0.438651756403294,
      0.43849564682930076,
      0.4380752773995095,
      0.43790604161455277,
      0.4378098180319401,
      0.43770977024068225,
      0.43776045828423604,
      0.4376263345809693,
      0.43766955245048444,
      0.43755592944774224,
      0.4374700318625633,
      0.4374772438343535,
      0.4374658831890593,
      0.4375339080678656,
      0.43740754634776013,
      0.43741753722759,
      0.43740327776746546,
      0.4373784008812397,
      0.4373885712725051,
      0.4373952933448426,
      0.4373479073986094,
      0.4373213599336908,
      0.43732134509593884,
      0.43731338927086366,
      0.437332092510893,
      0.4373803918031936,
      0.43732947827653684,
      0.43729716697905924,
      0.4372955320997441,
      0.4372885155550977,
      0.4373623523306339,
      0.4372929613640968,
      0.43725866199807917,
      0.43726895267659044,
      0.4372590017445544,
      0.4372800424377969,
      0.43721985106772565,
      0.43727141276318976,
      0.437247108779055,
      0.4372446967566267,
      0.4372998022018595,
      0.43728887857274806,
      0.4372556230489244,
      0.43724693586217594
    ],
    "test_loss": 0.437512668529875,
    "total_training_time": 18686.917143583298,
    "best_val_loss": 0.43721985106772565,
    "experiment_dir": "experiments/lstm-50-epochs-48-batch-size"
  }
}